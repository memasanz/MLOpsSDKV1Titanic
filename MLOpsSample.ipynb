{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove below from your notebook, example of setting variables in key vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env_name = \"Prediction_env\"\n",
    "experiment_folder = 'devOps_train_pipeline'\n",
    "cluster_name = \"wipfli-cluster\"\n",
    "conda_yml_file = './Environment/Prediction_env.yml'\n",
    "model_name = 'wipfli'\n",
    "prefix = 'wipfli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging\n",
    "from azureml.core.model import Model\n",
    "from azureml.exceptions import WebserviceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.47.0 to work with xmm-devops-final-dev\n",
      "Run By Notebook:False\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "import os, shutil\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "def get_environment_variables():\n",
    "    global envs\n",
    "    global run_by_notebook \n",
    "    run_by_notebook = False\n",
    "    environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "                         'subscriptionId', 'resourceGroup']\n",
    "    envs = {}\n",
    "    for x in environment_variables:\n",
    "        if os.environ.get(x) == None:\n",
    "            #get the values from keyvault\n",
    "            run_by_notebook = True\n",
    "            print('retrieve from key vault, value is None: ' + x)\n",
    "            ws = Workspace.from_config()\n",
    "            keyvault = ws.get_default_keyvault()\n",
    "            kv_results = keyvault.get_secrets(environment_variables)\n",
    "            envs = kv_results\n",
    "            for x in envs:\n",
    "                os.environ.setdefault(x, envs[x])\n",
    "            exit\n",
    "        else:\n",
    "            envs[x] = os.environ.get(x)\n",
    "    return run_by_notebook\n",
    "\n",
    "\n",
    "\n",
    "get_environment_variables()\n",
    "sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "                                    service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "                                    service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "ws = Workspace.get(name=envs['wsName'],\n",
    "                       auth=sp,\n",
    "                       subscription_id=envs['subscriptionId'],\n",
    "                       resource_group=envs['resourceGroup'])\n",
    "ws.get_details()\n",
    "\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
    "print('Run By Notebook:' + str(run_by_notebook))\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    initial_model = Model(ws, model_name)\n",
    "    inital_model_version = initial_model.version\n",
    "except WebserviceException :\n",
    "    inital_model_version = 0\n",
    "print('inital_model_version = ' + str(inital_model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devOps_train_pipeline\n",
      "continue run_outputs directory does not exits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "run_path = './run_outputs'\n",
    "try:\n",
    "    shutil.rmtree(run_path)\n",
    "except:\n",
    "    print('continue run_outputs directory does not exits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/eastus/workspaces/d804027a-0ec6-475a-9b96-b16d84c39b43/environments/Prediction-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221010.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"Prediction-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.5\",\n",
       "                \"scikit-learn\",\n",
       "                \"ipykernel\",\n",
       "                \"matplotlib\",\n",
       "                \"pandas\",\n",
       "                \"pip\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"pyarrow\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"Icingprediction_env\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(\"Prediction-env\", conda_yml_file)\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prediction_env'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "\n",
    "try:\n",
    "    env = Environment.from_conda_specification(\"Prediction_env\", conda_yml_file)\n",
    "    env.register(workspace=ws)\n",
    "    registered_env = Environment.get(ws, registered_env_name)\n",
    "    pipeline_run_config = RunConfiguration()\n",
    "    \n",
    "    # Use the compute you created above. \n",
    "    pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "    # Assign the environment to the run configuration\n",
    "    pipeline_run_config.environment = registered_env\n",
    "    print (\"Run configuration created.\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "??PipelineParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to create pipeline data and parameters\n",
      "creating testing & training data\n"
     ]
    }
   ],
   "source": [
    "print('about to create pipeline data and parameters')\n",
    "model_file         = PipelineData(name='model_file', datastore=default_ds)\n",
    "model_name         = PipelineParameter(\"model_name\", default_value='wipfli')\n",
    "model_desc         = PipelineParameter(\"model_desc\", default_value='description')\n",
    "raw_file_location  = PipelineParameter(name=\"raw_file_location\", default_value='Wipfli/raw_data.csv')\n",
    "\n",
    "print('creating testing & training data')\n",
    "\n",
    "training_data  = OutputFileDatasetConfig(name='training_data', destination=(default_ds, 'training_data/{run-id}')).read_delimited_files().register_on_complete(name=  'training_data')\n",
    "testing_data   = OutputFileDatasetConfig(name='testing_data', destination=(default_ds, 'testing_data/{run-id}')).read_delimited_files().register_on_complete(name=  'testing_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": [
     "magic_cells"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting devOps_train_pipeline/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/training.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from azureml.core import Run, Dataset, Workspace, Experiment\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, log_loss\n",
    "\n",
    "# Calculate model performance metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--raw_file_location\", type=str)\n",
    "    parser.add_argument('--training_data', dest='training_data', required=True)\n",
    "    parser.add_argument('--testing_data', dest='testing_data', required=True)\n",
    "    parser.add_argument('--model_file', dest='model_file', required=True)\n",
    "    parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def buildpreprocessorpipeline(X_raw):\n",
    "    categorical_features = X_raw.select_dtypes(include=['object']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=\"missing\")),\n",
    "                                              ('onehotencoder', OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ], remainder=\"drop\")\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def model_train(LABEL, df, run, training_data, testing_data):  \n",
    "#     y_raw = df[LABEL]\n",
    "#     X_raw = df.drop([LABEL], axis=1)\n",
    "    \n",
    "     # Train test split\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "    \n",
    "    train1 = train.dropna()\n",
    "    test1 = test.dropna()\n",
    "    \n",
    "    X_train = train1\n",
    "    y_train = train1[LABEL]\n",
    "    \n",
    "    X_test = test1\n",
    "    y_test = test1[LABEL]\n",
    "\n",
    "    \n",
    "    #save train and test datasets\n",
    "    os.makedirs(training_data, exist_ok=True)\n",
    "    os.makedirs(testing_data, exist_ok=True)\n",
    "\n",
    "    train1.to_csv(os.path.join(training_data, 'training_data.csv'), index=False )\n",
    "    test1.to_csv(os.path.join(testing_data, 'testing_data.csv'), index=False)\n",
    "\n",
    "    \n",
    "    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    preprocessor = buildpreprocessorpipeline(X_train)\n",
    "    \n",
    "    #estimator instance\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', lg)])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    # calculate AUC\n",
    "    y_scores = clf.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "    run.log('AUC', np.float(auc))\n",
    "\n",
    "    \n",
    "    # calculate test accuracy\n",
    "    y_hat = clf.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "    run.log('Accuracy', np.float(acc))\n",
    "\n",
    "\n",
    "    precisions, recall, f1_score, _ = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
    "    \n",
    "    run.log('precision', np.float(precisions[1]))\n",
    "    run.log('recall', np.float(recall[1]))\n",
    "    y_pred_prob = clf.predict_proba(X_test)[::,1]\n",
    "    run.log('Log-Loss', np.float(log_loss(y_test, y_pred_prob)))\n",
    "    \n",
    "    run.parent.log('precision', np.float(precisions[1]))\n",
    "    run.parent.log('recall', np.float(recall[1]))\n",
    "    run.parent.log('Log-Loss', np.float(log_loss(y_test, y_pred_prob)))\n",
    "\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    run.log_image(name = \"ROC\", plot = fig)\n",
    "    plt.show()\n",
    "\n",
    "    # plot confusion matrix\n",
    "    # Generate confusion matrix\n",
    "    cmatrix = confusion_matrix(y_test, y_hat)\n",
    "    cmatrix_json = {\n",
    "        \"schema_type\": \"confusion_matrix\",\n",
    "           \"schema_version\": \"v1\",\n",
    "           \"data\": {\n",
    "               \"class_labels\": [\"0\", \"1\"],\n",
    "               \"matrix\": [\n",
    "                   [int(x) for x in cmatrix[0]],\n",
    "                   [int(x) for x in cmatrix[1]]\n",
    "               ]\n",
    "           }\n",
    "    }\n",
    "    \n",
    "    run.log_confusion_matrix('ConfusionMatrix_Test', cmatrix_json)\n",
    "\n",
    "    return clf\n",
    "    # Save the trained model\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    # Create an Azure ML experiment in your workspace\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    raw_file_location = args.raw_file_location\n",
    "    training_data = args.training_data\n",
    "    testing_data = args.testing_data\n",
    "    model_file = args.model_file\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    \n",
    "    run = Run.get_context()\n",
    "\n",
    "    dataset_dir = './dataset/'\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    ws = run.experiment.workspace\n",
    "    ds = ws.get_default_datastore()\n",
    "    \n",
    "    print(ws)\n",
    "    \n",
    "\n",
    "    print(\"Loading Data...\")\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path = [(ds, raw_file_location)])\n",
    "    # Load a TabularDataset & save into pandas DataFrame\n",
    "    df = dataset.to_pandas_dataframe()\n",
    "    \n",
    "    print(df.head(5))\n",
    " \n",
    "    model = model_train('Survived', df, run, training_data, testing_data)\n",
    "    \n",
    "    # Save the trained model\n",
    "#     model_file = 'titanic_model.pkl'\n",
    "#     joblib.dump(value=model, filename='./outputs/' + model_file)\n",
    "#     os.makedirs(model_file_output, exist_ok=True)\n",
    "#     shutil.copyfile('./outputs/' + model_file, os.path.join(model_file_output, 'titanic_model.pkl'))\n",
    "\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "    model_file_name = model_name  + '.pkl'\n",
    "    file_name = './outputs/' +model_file_name\n",
    "\n",
    "    joblib.dump(value=model, filename=file_name)\n",
    "\n",
    "    os.makedirs(model_file, exist_ok=True)\n",
    "\n",
    "    shutil.copyfile(file_name, os.path.join(model_file, model_file_name))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_model_step = PythonScriptStep(\n",
    "    name='Get Data and Create Model',\n",
    "    script_name='training.py',\n",
    "    arguments =['--raw_file_location', raw_file_location,\n",
    "                '--training_data', testing_data,\n",
    "                '--testing_data', testing_data,\n",
    "                '--model_file', model_file,\n",
    "                '--model_name', model_name\n",
    "               ],\n",
    "    inputs=[],\n",
    "    outputs=[model_file, training_data, testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": [
     "magic_cells"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting devOps_train_pipeline/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/eval.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "parser.add_argument('--model_file', dest = 'model_file',  required=True)\n",
    "parser.add_argument('--model_desc', dest = 'model_desc',  required=True)\n",
    "parser.add_argument('--deploy_file', dest='deploy_file', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_name = args.model_name\n",
    "model_file = args.model_file\n",
    "model_desc = args.model_desc\n",
    "\n",
    "deploy_file = args.deploy_file\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "current_model_precision = float(metrics['precision'])\n",
    "current_model_recall = float(metrics['recall'])\n",
    "current_model_logloss = float(metrics['Log-Loss'])\n",
    "# Get current model from workspace\n",
    "\n",
    "model_description = model_desc\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'precision': current_model_precision, 'recall': current_model_recall}\n",
    "\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "\n",
    "#upload model to the outputs directory\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "model_file_name = model_name  + '.pkl'\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['precision']) < current_model_precision:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy_model'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('do not deploy model'))\n",
    "            \n",
    "        run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deploy_file = PipelineData(name='deploy_file', datastore=default_ds)\n",
    "\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='eval.py',\n",
    "    arguments=[\n",
    "        '--model_name', model_name,\n",
    "        '--model_file', model_file,\n",
    "        '--model_desc', model_desc,\n",
    "        '--deploy_file', deploy_file,       \n",
    "    ],\n",
    "    inputs=[model_file.as_input('model_file'),\n",
    "            training_data.as_input(name='training_data'),\n",
    "            testing_data.as_input(name='testing_data')\n",
    "           ],\n",
    "    outputs=[ deploy_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Get Data and Create Model [54e44115][c9337be5-9490-438a-956e-b94374c41023], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [6390cc7b][75d043d3-9ddf-4a93-be0e-2b136247c569], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 86cd6b77-86af-4605-a233-b97b09578723\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/86cd6b77-86af-4605-a233-b97b09578723?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRunId: 86cd6b77-86af-4605-a233-b97b09578723\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/86cd6b77-86af-4605-a233-b97b09578723?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 13542de9-56f7-4770-91f0-c98fc3d65c91\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/13542de9-56f7-4770-91f0-c98fc3d65c91?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Get Data and Create Model ) Status: NotStarted\n",
      "StepRun( Get Data and Create Model ) Status: Running\n"
     ]
    }
   ],
   "source": [
    "## Create Pipeline Steps\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_model_step, evaluate_and_register_step])\n",
    "if run_by_notebook:\n",
    "    experiment = Experiment(ws, 'AML_Manual_PipelineTraining')\n",
    "else:\n",
    "    experiment = Experiment(ws, 'AML_AutoDevOps_PipelineTraining')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    final_model = Model(ws, model_name)\n",
    "    final_model_version = final_model.version\n",
    "except WebserviceException :\n",
    "    final_model_version = 0\n",
    "    \n",
    "print('inital_model_version = ' + str(inital_model_version))\n",
    "print('final_model_version= ' + str(final_model_version))\n",
    "\n",
    "status = run.get_status()\n",
    "run_details = run.get_details()\n",
    "\n",
    "print((run_details))\n",
    "print(run_details['runId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_model_version > 0 and (inital_model_version != final_model_version):\n",
    "    deploy = 'deploy'\n",
    "    model_details = {\n",
    "        \"name\" : final_model.name,\n",
    "        \"version\": final_model.version,\n",
    "        \"properties\": final_model.properties,\n",
    "        \"nextstep\": \"deploy\"\n",
    "    }\n",
    "    print(model_details)\n",
    "else:\n",
    "    deploy = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in final_model.properties:\n",
    "    print(x)\n",
    "    print(final_model.properties[x])\n",
    "\n",
    "\n",
    "print (final_model.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "outputfolder = 'run_outputs'\n",
    "os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "if (final_model_version != inital_model_version):\n",
    "    print('new model registered')\n",
    "    with open(os.path.join(outputfolder, 'deploy_details.json'), \"w+\") as f:\n",
    "        f.write(str(model_details))\n",
    "    model_name = prefix\n",
    "    model_list = Model.list(ws, name=model_name, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model_file_name = prefix + '.pkl'\n",
    "    shutil.copyfile(model_file_name,  os.path.join(outputfolder,model_file_name))\n",
    "    \n",
    "    #create model.yml file.\n",
    "    with open(os.path.join(outputfolder, 'model.yml'), \"w+\") as f:\n",
    "        f.write('$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json \\n')\n",
    "        f.write('name: ' + model_details['name'] + '\\n')\n",
    "        #f.write('version: ' + str(final_model.version)  + '\\n')\n",
    "        f.write('path: ' + prefix + '.pkl \\n')\n",
    "        f.write('description: Model created from local file. \\n')\n",
    "        if len(final_model.properties) > 0:\n",
    "            f.write('properties: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            f.write('\\n')\n",
    "            f.write('tags: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            \n",
    "    \n",
    "with open(os.path.join(outputfolder, 'run_details.json'), \"w+\") as f:\n",
    "    print(run_details)\n",
    "    f.write(str(run_details))\n",
    "\n",
    "with open(os.path.join(outputfolder, \"run_number.json\"), \"w+\") as f:\n",
    "    f.write(run_details['runId'])\n",
    "    \n",
    "with open(os.path.join(outputfolder, \"deploy.txt\"), \"w+\") as f:\n",
    "    f.write(deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "def published_pipeline_to_pipeline_endpoint(\n",
    "    workspace,\n",
    "    published_pipeline,\n",
    "    pipeline_endpoint_name,\n",
    "    pipeline_endpoint_description=\"Endpoint to Training pipeline\",\n",
    "):\n",
    "    try:\n",
    "        pipeline_endpoint = PipelineEndpoint.get(\n",
    "            workspace=workspace, name=pipeline_endpoint_name\n",
    "        )\n",
    "        print(\"using existing PipelineEndpoint...\")\n",
    "        pipeline_endpoint.add_default(published_pipeline)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        # create PipelineEndpoint if it doesn't exist\n",
    "        print(\"PipelineEndpoint does not exist, creating one for you...\")\n",
    "        pipeline_endpoint = PipelineEndpoint.publish(\n",
    "            workspace=workspace,\n",
    "            name=pipeline_endpoint_name,\n",
    "            pipeline=published_pipeline,\n",
    "            description=pipeline_endpoint_description\n",
    "        )\n",
    "\n",
    "if deploy == 'deploy':\n",
    "    print('deploy Training Pipeline')\n",
    "    pipeline_endpoint_name = 'Training Pipeline'\n",
    "    pipeline_endpoint_description = 'Endpoint to Training pipeline'\n",
    "\n",
    "    published_pipeline = pipeline.publish(name=pipeline_endpoint_name,\n",
    "                                         description=pipeline_endpoint_description,\n",
    "                                         continue_on_step_failure=False)\n",
    "\n",
    "    published_pipeline_to_pipeline_endpoint(\n",
    "        workspace=ws,\n",
    "        published_pipeline=published_pipeline,\n",
    "        pipeline_endpoint_name=pipeline_endpoint_name,\n",
    "        pipeline_endpoint_description=pipeline_endpoint_description\n",
    "    )\n",
    "else:\n",
    "    print('do not publish pipeline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
