{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove below from your notebook, example of setting variables in key vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env_name = \"Prediction_env\"\n",
    "experiment_folder = 'devOps_train_pipeline'\n",
    "cluster_name = \"wipfli-cluster\"\n",
    "conda_yml_file = './Environment/Prediction_env.yml'\n",
    "model_name = 'wipfli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging\n",
    "from azureml.core.model import Model\n",
    "from azureml.exceptions import WebserviceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.47.0 to work with xmm-devops-final-dev\n",
      "Run By Notebook:False\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "import os, shutil\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "def get_environment_variables():\n",
    "    global envs\n",
    "    global run_by_notebook \n",
    "    run_by_notebook = False\n",
    "    environment_variables = ['tenantId', 'servicePrincipalId', 'servicePrincipalPassword', 'wsName', \n",
    "                         'subscriptionId', 'resourceGroup']\n",
    "    envs = {}\n",
    "    for x in environment_variables:\n",
    "        if os.environ.get(x) == None:\n",
    "            #get the values from keyvault\n",
    "            run_by_notebook = True\n",
    "            print('retrieve from key vault, value is None: ' + x)\n",
    "            ws = Workspace.from_config()\n",
    "            keyvault = ws.get_default_keyvault()\n",
    "            kv_results = keyvault.get_secrets(environment_variables)\n",
    "            envs = kv_results\n",
    "            for x in envs:\n",
    "                os.environ.setdefault(x, envs[x])\n",
    "            exit\n",
    "        else:\n",
    "            envs[x] = os.environ.get(x)\n",
    "    return run_by_notebook\n",
    "\n",
    "\n",
    "\n",
    "get_environment_variables()\n",
    "sp = ServicePrincipalAuthentication(tenant_id=envs['tenantId'], # tenantID\n",
    "                                    service_principal_id=envs['servicePrincipalId'], # clientId\n",
    "                                    service_principal_password=envs['servicePrincipalPassword']) # clientSecret\n",
    "ws = Workspace.get(name=envs['wsName'],\n",
    "                       auth=sp,\n",
    "                       subscription_id=envs['subscriptionId'],\n",
    "                       resource_group=envs['resourceGroup'])\n",
    "ws.get_details()\n",
    "\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
    "print('Run By Notebook:' + str(run_by_notebook))\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    initial_model = Model(ws, model_name)\n",
    "    inital_model_version = initial_model.version\n",
    "except WebserviceException :\n",
    "    inital_model_version = 0\n",
    "print('inital_model_version = ' + str(inital_model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devOps_train_pipeline\n",
      "continue run_outputs directory does not exits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)\n",
    "\n",
    "run_path = './run_outputs'\n",
    "try:\n",
    "    shutil.rmtree(run_path)\n",
    "except:\n",
    "    print('continue run_outputs directory does not exits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/eastus/workspaces/d804027a-0ec6-475a-9b96-b16d84c39b43/environments/Prediction-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221010.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"Prediction-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.5\",\n",
       "                \"scikit-learn\",\n",
       "                \"ipykernel\",\n",
       "                \"matplotlib\",\n",
       "                \"pandas\",\n",
       "                \"pip\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"pyarrow\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"Icingprediction_env\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(\"Prediction-env\", conda_yml_file)\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prediction_env'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "\n",
    "try:\n",
    "    env = Environment.from_conda_specification(\"Prediction_env\", conda_yml_file)\n",
    "    env.register(workspace=ws)\n",
    "    registered_env = Environment.get(ws, registered_env_name)\n",
    "    pipeline_run_config = RunConfiguration()\n",
    "    \n",
    "    # Use the compute you created above. \n",
    "    pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "    # Assign the environment to the run configuration\n",
    "    pipeline_run_config.environment = registered_env\n",
    "    print (\"Run configuration created.\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data  = OutputFileDatasetConfig(name='training_data', destination=(default_ds, prefix + '_training_data/{run-id}')).read_delimited_files().register_on_complete(name= prefix + '_training_data')\n",
    "testing_data   = OutputFileDatasetConfig(name='testing_data', destination=(default_ds, prefix + '_testing_data/{run-id}')).read_delimited_files().register_on_complete(name= prefix + '_testing_data')\n",
    "\n",
    "model_file     = PipelineData(name='model_file', datastore=default_ds)\n",
    "model_name         = PipelineParameter(\"model_name\", default_value=model_name)\n",
    "model_desc         = PipelineParameter(\"model_desc\", default_value=model_name + ' description')\n",
    "raw_file_location  = PipelineParameter(name=\"raw_file_location\", default_value='Wipfli/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": [
     "magic_cells"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting devOps_train_pipeline/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/training.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from azureml.core import Run, Dataset, Workspace, Experiment\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, log_loss\n",
    "\n",
    "# Calculate model performance metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "def getRuntimeArgs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--raw_file_location\", type=str)\n",
    "    parser.add_argument('--training_data', dest='training_data', required=True)\n",
    "    parser.add_argument('--testing_data', dest='testing_data', required=True)\n",
    "    parser.add_argument('--model_file', dest='model_file', required=True)\n",
    "    parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def buildpreprocessorpipeline(X_raw):\n",
    "    categorical_features = X_raw.select_dtypes(include=['object']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=\"missing\")),\n",
    "                                              ('onehotencoder', OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ], remainder=\"drop\")\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def model_train(LABEL, df, run, training_data, testing_data):  \n",
    "#     y_raw = df[LABEL]\n",
    "#     X_raw = df.drop([LABEL], axis=1)\n",
    "    \n",
    "     # Train test split\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "    \n",
    "    train1 = train.dropna()\n",
    "    test1 = test.dropna()\n",
    "    \n",
    "    X_train = train1\n",
    "    y_train = train1[LABEL]\n",
    "    \n",
    "    X_test = test1\n",
    "    y_test = test1[LABEL]\n",
    "\n",
    "    \n",
    "    #save train and test datasets\n",
    "    os.makedirs(training_data, exist_ok=True)\n",
    "    os.makedirs(testing_data, exist_ok=True)\n",
    "\n",
    "    train1.to_csv(os.path.join(training_data, 'training_data.csv'), index=False )\n",
    "    test1.to_csv(os.path.join(testing_data, 'testing_data.csv'), index=False)\n",
    "\n",
    "    \n",
    "    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    preprocessor = buildpreprocessorpipeline(X_train)\n",
    "    \n",
    "    #estimator instance\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', lg)])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    # calculate AUC\n",
    "    y_scores = clf.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "    run.log('AUC', np.float(auc))\n",
    "\n",
    "    \n",
    "    # calculate test accuracy\n",
    "    y_hat = clf.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "    run.log('Accuracy', np.float(acc))\n",
    "\n",
    "\n",
    "    precisions, recall, f1_score, _ = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
    "    \n",
    "    run.log('precision', np.float(precisions[1]))\n",
    "    run.log('recall', np.float(recall[1]))\n",
    "    y_pred_prob = clf.predict_proba(X_test)[::,1]\n",
    "    run.log('Log-Loss', np.float(log_loss(y_test, y_pred_prob)))\n",
    "    \n",
    "    run.parent.log('precision', np.float(precisions[1]))\n",
    "    run.parent.log('recall', np.float(recall[1]))\n",
    "    run.parent.log('Log-Loss', np.float(log_loss(y_test, y_pred_prob)))\n",
    "\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat)\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    run.log_image(name = \"ROC\", plot = fig)\n",
    "    plt.show()\n",
    "\n",
    "    # plot confusion matrix\n",
    "    # Generate confusion matrix\n",
    "    cmatrix = confusion_matrix(y_test, y_hat)\n",
    "    cmatrix_json = {\n",
    "        \"schema_type\": \"confusion_matrix\",\n",
    "           \"schema_version\": \"v1\",\n",
    "           \"data\": {\n",
    "               \"class_labels\": [\"0\", \"1\"],\n",
    "               \"matrix\": [\n",
    "                   [int(x) for x in cmatrix[0]],\n",
    "                   [int(x) for x in cmatrix[1]]\n",
    "               ]\n",
    "           }\n",
    "    }\n",
    "    \n",
    "    run.log_confusion_matrix('ConfusionMatrix_Test', cmatrix_json)\n",
    "\n",
    "    return clf\n",
    "    # Save the trained model\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    # Create an Azure ML experiment in your workspace\n",
    "    args = getRuntimeArgs()\n",
    "    \n",
    "    raw_file_location = args.raw_file_location\n",
    "    training_data = args.training_data\n",
    "    testing_data = args.testing_data\n",
    "    model_file = args.model_file\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    \n",
    "    run = Run.get_context()\n",
    "\n",
    "    dataset_dir = './dataset/'\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    ws = run.experiment.workspace\n",
    "    ds = ws.get_default_datastore()\n",
    "    \n",
    "    print(ws)\n",
    "    \n",
    "\n",
    "    print(\"Loading Data...\")\n",
    "    dataset = Dataset.Tabular.from_delimited_files(path = [(ds, raw_file_location)])\n",
    "    # Load a TabularDataset & save into pandas DataFrame\n",
    "    df = dataset.to_pandas_dataframe()\n",
    "    \n",
    "    print(df.head(5))\n",
    " \n",
    "    model = model_train('Survived', df, run, training_data, testing_data)\n",
    "    \n",
    "    # Save the trained model\n",
    "#     model_file = 'titanic_model.pkl'\n",
    "#     joblib.dump(value=model, filename='./outputs/' + model_file)\n",
    "#     os.makedirs(model_file_output, exist_ok=True)\n",
    "#     shutil.copyfile('./outputs/' + model_file, os.path.join(model_file_output, 'titanic_model.pkl'))\n",
    "\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "    model_file_name = model_name  + '.pkl'\n",
    "    file_name = './outputs/' +model_file_name\n",
    "\n",
    "    joblib.dump(value=model, filename=file_name)\n",
    "\n",
    "    os.makedirs(model_file, exist_ok=True)\n",
    "\n",
    "    shutil.copyfile(file_name, os.path.join(model_file, model_file_name))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_model_step = PythonScriptStep(\n",
    "    name='Get Data and Create Model',\n",
    "    script_name='training.py',\n",
    "    arguments =['--raw_file_location', raw_file_location,\n",
    "                '--training_data', testing_data,\n",
    "                '--testing_data', testing_data,\n",
    "                '--model_file', model_file,\n",
    "                '--model_name', model_name\n",
    "               ],\n",
    "    inputs=[],\n",
    "    outputs=[model_file, training_data, testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": [
     "magic_cells"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting devOps_train_pipeline/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/eval.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_name', dest='model_name', required=True)\n",
    "parser.add_argument('--model_file', dest = 'model_file',  required=True)\n",
    "parser.add_argument('--model_desc', dest = 'model_desc',  required=True)\n",
    "parser.add_argument('--deploy_file', dest='deploy_file', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_name = args.model_name\n",
    "model_file = args.model_file\n",
    "model_desc = args.model_desc\n",
    "\n",
    "deploy_file = args.deploy_file\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "current_model_precision = float(metrics['precision'])\n",
    "current_model_recall = float(metrics['recall'])\n",
    "current_model_logloss = float(metrics['Log-Loss'])\n",
    "# Get current model from workspace\n",
    "\n",
    "model_description = model_desc\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'precision': current_model_precision, 'recall': current_model_recall}\n",
    "\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "\n",
    "#upload model to the outputs directory\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "model_file_name = model_name  + '.pkl'\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['precision']) < current_model_precision:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/' + model_file_name, model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties=updated_tags)\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy_model'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('do not deploy model'))\n",
    "            \n",
    "        run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deploy_file = PipelineData(name='deploy_file', datastore=default_ds)\n",
    "\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='eval.py',\n",
    "    arguments=[\n",
    "        '--model_name', model_name,\n",
    "        '--model_file', model_file,\n",
    "        '--model_desc', model_desc,\n",
    "        '--deploy_file', deploy_file,       \n",
    "    ],\n",
    "    inputs=[model_file.as_input('model_file'),\n",
    "            training_data.as_input(name='training_data'),\n",
    "            testing_data.as_input(name='testing_data')\n",
    "           ],\n",
    "    outputs=[ deploy_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Get Data and Create Model [32cf1268][c9337be5-9490-438a-956e-b94374c41023], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [93e5cf9a][17466abb-3034-49ba-b203-0cdbb9edf3aa], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 1bc148c2-923d-4237-a582-05548a9538d7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/1bc148c2-923d-4237-a582-05548a9538d7?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRunId: 1bc148c2-923d-4237-a582-05548a9538d7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/1bc148c2-923d-4237-a582-05548a9538d7?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 477c6dd5-c1eb-47bd-81dc-9502b2075620\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/477c6dd5-c1eb-47bd-81dc-9502b2075620?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Get Data and Create Model ) Status: Queued\n",
      "StepRun( Get Data and Create Model ) Status: Running\n",
      "\n",
      "StepRun(Get Data and Create Model) Execution Summary\n",
      "=====================================================\n",
      "StepRun( Get Data and Create Model ) Status: Finished\n",
      "{'runId': '477c6dd5-c1eb-47bd-81dc-9502b2075620', 'target': 'wipfli-cluster', 'status': 'Completed', 'startTimeUtc': '2022-12-15T15:38:14.120734Z', 'endTimeUtc': '2022-12-15T15:38:48.012651Z', 'services': {}, 'properties': {'ContentSnapshotId': '415fd688-97a4-4f5f-8ece-2c60e4778d09', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c9337be5-9490-438a-956e-b94374c41023', 'azureml.moduleName': 'Get Data and Create Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '32cf1268', 'azureml.pipelinerunid': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipeline': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': 'ee0063a9-aada-42c4-a19a-f09d7c95d78b', 'registeredId': '51056094-59c1-4b79-b3a7-567767e4d674', 'registeredVersion': '20'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'training_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'wipfli_training_data/477c6dd5-c1eb-47bd-81dc-9502b2075620')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"ee0063a9-aada-42c4-a19a-f09d7c95d78b\",\n",
      "    \"name\": \"wipfli_training_data\",\n",
      "    \"version\": 20,\n",
      "    \"workspace\": \"Workspace.create(name='xmm-devops-final-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='xmm-devops-final-dev-rg')\"\n",
      "  }\n",
      "}}, {'identifier': {'savedId': '45372c46-a798-4a0f-b049-0225f45bd417', 'registeredId': '6adc242d-429a-49be-adb9-d1c7a688372c', 'registeredVersion': '20'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'testing_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'wipfli_testing_data/477c6dd5-c1eb-47bd-81dc-9502b2075620')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"45372c46-a798-4a0f-b049-0225f45bd417\",\n",
      "    \"name\": \"wipfli_testing_data\",\n",
      "    \"version\": 20,\n",
      "    \"workspace\": \"Workspace.create(name='xmm-devops-final-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='xmm-devops-final-dev-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'training.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--raw_file_location', '$AML_PARAMETER_raw_file_location', '--training_data', 'DatasetOutputConfig:testing_data', '--testing_data', 'DatasetOutputConfig:testing_data', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_name', '$AML_PARAMETER_model_name'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'wipfli-cluster', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/477c6dd5-c1eb-47bd-81dc-9502b2075620/model_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {'training_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'wipfli_training_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'wipfli_training_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipelineRun.moduleNodeId': '32cf1268', 'azureml.pipelineRun.outputPortName': 'training_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"081ee6fe-d2ab-4532-bf9d-2546f1b5a1c8\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"6b145183-672d-4f68-89ea-0a02bc8b0072\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}, 'testing_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'wipfli_testing_data/{run-id}'}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'wipfli_testing_data', 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipelineRun.moduleNodeId': '32cf1268', 'azureml.pipelineRun.outputPortName': 'testing_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"66005466-a7f6-4eb8-8b7f-aee32cbab05f\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"f844968e-2015-4edf-8a66-f8a6b4791029\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Prediction_env', 'version': '1', 'assetId': 'azureml://locations/eastus/workspaces/d804027a-0ec6-475a-9b96-b16d84c39b43/environments/Prediction_env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'Icingprediction_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221010.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_raw_file_location': 'Wipfli/raw_data.csv', 'AML_PARAMETER_model_name': 'wipfli'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=P6zAeZ8o34R80ItepnsNDiXZcsarUS2y%2BeuJZkLrHkE%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=Tz24os8QbmvkWwMAmuDqTGfQ7MrjYl7cf0i0bYcQun4%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2022-12-15-15': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/dataprep/0/rslex.log.2022-12-15-15?sv=2019-07-07&sr=b&sig=BY0%2BbghGqUlUXn%2F7oZKsGe9Mw%2BuZ9eLTVcRBGaVIGrA%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=V6HComgkVpzbzISUCiUHaB7keskkmLKRid8xWrNASx0%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=AzTyW7g3%2BWbJR3uYjyy8pOlNIXchY8l3eZ6oTZIyR1E%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=hb6yeBrPXlH9nnMVJCtaexkP2Z7RYsl0nfCaR%2Bc4iK0%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A33Z&ske=2022-12-16T22%3A57%3A33Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A42Z&se=2022-12-15T23%3A38%3A42Z&sp=r', 'user_logs/std_log.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=jat0CeoT0JiZdQyDd81GbcULZOCBqSlnNPqWQQeiWIQ%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A30%3A02Z&ske=2022-12-16T22%3A40%3A02Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=ocrPylI2NKEsqMvW3ot%2FJfXpubNFd%2FV50fgAtBwtEGc%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=p%2BmH9xXQR7ZURxvYqdUDWzqrGeC%2FkHqlnKUxGIIHuZ0%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/data_capability/rslex.log.2022-12-15-15': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/data_capability/rslex.log.2022-12-15-15?sv=2019-07-07&sr=b&sig=IY7OX6VU8%2Bo%2B5L23GkiK5I%2FbDP9yXBLwHXBSonp7NmQ%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=m8vWL3XEBASaW94SyL03zAcTvUEntjfWyPYpHgQ4IT8%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=UNk0QaqgbzIOD0G6kCn0XRHiNOq%2B%2BJEWisD%2F3bizn60%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=9BYTpmTYyFSLgdwyvFJd7TlFKH1SyOS1liPYFyCQFRY%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=9GUbhvE4B3rAqSOBZJZ8s0PzdaUDCqyOIh8EpD4zXJE%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.477c6dd5-c1eb-47bd-81dc-9502b2075620/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=1ilh4UalJxJvIL84J6BpFOMs3Ugc4Zay2XnbHBG%2FHP8%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A50Z&se=2022-12-15T23%3A38%3A50Z&sp=r'}, 'submittedBy': '25f345b2-3dfd-4e27-a4f0-cebf07be4f51'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: d42a06cf-dd39-453a-ac78-c950393fdba2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/d42a06cf-dd39-453a-ac78-c950393fdba2?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/xmm-devops-final-dev-rg/workspaces/xmm-devops-final-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Evaluate and Register Model ) Status: NotStarted\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': 'd42a06cf-dd39-453a-ac78-c950393fdba2', 'target': 'wipfli-cluster', 'status': 'Completed', 'startTimeUtc': '2022-12-15T15:38:58.335881Z', 'endTimeUtc': '2022-12-15T15:39:14.415392Z', 'services': {}, 'properties': {'ContentSnapshotId': '415fd688-97a4-4f5f-8ece-2c60e4778d09', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '17466abb-3034-49ba-b203-0cdbb9edf3aa', 'azureml.moduleName': 'Evaluate and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '93e5cf9a', 'azureml.pipelinerunid': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipeline': '1bc148c2-923d-4237-a582-05548a9538d7', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '957ad9e7-abc9-4780-a6b5-492360e77e64'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}, {'dataset': {'id': '01112eb8-80c5-4c83-8f01-3255d9ae42bc'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'testing_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'eval.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_file', '$AZUREML_DATAREFERENCE_model_file', '--model_desc', '$AML_PARAMETER_model_desc', '--deploy_file', '$AZUREML_DATAREFERENCE_deploy_file'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'wipfli-cluster', 'dataReferences': {'model_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/477c6dd5-c1eb-47bd-81dc-9502b2075620/model_file', 'pathOnCompute': None, 'overwrite': False}, 'deploy_file': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d42a06cf-dd39-453a-ac78-c950393fdba2/deploy_file', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'training_data': {'dataLocation': {'dataset': {'id': '957ad9e7-abc9-4780-a6b5-492360e77e64', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'training_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}, 'testing_data': {'dataLocation': {'dataset': {'id': '01112eb8-80c5-4c83-8f01-3255d9ae42bc', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'testing_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Prediction_env', 'version': '1', 'assetId': 'azureml://locations/eastus/workspaces/d804027a-0ec6-475a-9b96-b16d84c39b43/environments/Prediction_env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'Icingprediction_env', 'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221010.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'wipfli', 'AML_PARAMETER_model_desc': 'wipfli description'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=ouu%2BDwmuhqqkvhlMyhMWvFw4TzW3Xgy%2FY5YtWSdvHPw%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A56Z&se=2022-12-15T23%3A38%3A56Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=VIgkZsPDDO2BWsZp1KecfxA7YoXR3qKs0xJ5T4%2F34ik%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A56Z&se=2022-12-15T23%3A38%3A56Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=5GGLAjErWMEJYsGZqn5%2FMSeEaY3xkZNAhLeYbaqpiUo%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A56Z&se=2022-12-15T23%3A38%3A56Z&sp=r', 'user_logs/std_log.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=norpsyMWdXnkbk5EcHXJrFNKZL2DDPajW2f6Xdff1ps%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A12%3A56Z&ske=2022-12-16T22%3A22%3A56Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=wX3yspgiG3RsfoTIuX34A7ubnYyHmB%2FVS6%2B6BYyzBdk%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=aRpcPEb9iH2PR%2FjLT4EDD9KxJ4O1kRQ%2F%2FY9NEzmRgzE%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/data_capability/rslex.log.2022-12-15-15': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/data_capability/rslex.log.2022-12-15-15?sv=2019-07-07&sr=b&sig=sN8wrM2BZ5Fmt04TZ3QmgLtaTO38IdSmkYoR7LDjrQ4%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=7H7mALaNHLhR05Jj%2Bnv8LD2ImxPURCdCS0Ccn2yvIAU%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=1BZmV91NxzWlEYvujGjF1UwCVnlqQSCGCnDXWxxRmng%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=IeYALQ4n3XlqZ1si9Vg5N8PnFQtgS%2BzKpTkN6pANLAs%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=ms1G6AzKYRWQJPj6i91RTGAIj0sgt0PpfVoSOpmWE7I%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.d42a06cf-dd39-453a-ac78-c950393fdba2/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=3bXYGsvSR5xemFYVWhxpMP2p913gk15Q%2BRKyY7kPLnI%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A14%3A41Z&ske=2022-12-16T22%3A24%3A41Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A29%3A21Z&se=2022-12-15T23%3A39%3A21Z&sp=r'}, 'submittedBy': '25f345b2-3dfd-4e27-a4f0-cebf07be4f51'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '1bc148c2-923d-4237-a582-05548a9538d7', 'status': 'Completed', 'startTimeUtc': '2022-12-15T15:38:05.625252Z', 'endTimeUtc': '2022-12-15T15:39:15.460579Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"raw_file_location\":\"Wipfli/raw_data.csv\",\"model_name\":\"wipfli\",\"model_desc\":\"wipfli description\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2022-12-15T15:38:05.9496548+00:00\",\"EndTime\":\"2022-12-15T15:39:15.3717657+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.1bc148c2-923d-4237-a582-05548a9538d7/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=6z%2BOfoikYQX9IWYTJK%2BvfHYXLgcMrf9SWnk7PTP4NEk%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A35Z&ske=2022-12-16T22%3A57%3A35Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A46Z&se=2022-12-15T23%3A38%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.1bc148c2-923d-4237-a582-05548a9538d7/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=1kCPxMMlwZlsXsxAQ4YmDacljTELivqFRAg%2BVUi9%2Brw%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A35Z&ske=2022-12-16T22%3A57%3A35Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A46Z&se=2022-12-15T23%3A38%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://xmmdevopsfinal8028030861.blob.core.windows.net/azureml/ExperimentRun/dcid.1bc148c2-923d-4237-a582-05548a9538d7/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=IF5tlgSqK3MXz8oXBlyrP5OOKHB5PumVxeHxNIz0prc%3D&skoid=4f3a1769-367d-42f7-9cd0-8a00c94759c6&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-12-15T14%3A47%3A35Z&ske=2022-12-16T22%3A57%3A35Z&sks=b&skv=2019-07-07&st=2022-12-15T15%3A28%3A46Z&se=2022-12-15T23%3A38%3A46Z&sp=r'}, 'submittedBy': '25f345b2-3dfd-4e27-a4f0-cebf07be4f51'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Pipeline Steps\n",
    "pipeline = Pipeline(workspace=ws, steps=[train_model_step, evaluate_and_register_step])\n",
    "if run_by_notebook:\n",
    "    experiment = Experiment(ws, 'AML_Manual_PipelineTraining')\n",
    "else:\n",
    "    experiment = Experiment(ws, 'AML_AutoDevOps_PipelineTraining')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    final_model = Model(ws, model_name)\n",
    "    final_model_version = final_model.version\n",
    "except WebserviceException :\n",
    "    final_model_version = 0\n",
    "    \n",
    "print('inital_model_version = ' + str(inital_model_version))\n",
    "print('final_model_version= ' + str(final_model_version))\n",
    "\n",
    "status = run.get_status()\n",
    "run_details = run.get_details()\n",
    "\n",
    "print((run_details))\n",
    "print(run_details['runId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if final_model_version > 0 and (inital_model_version != final_model_version):\n",
    "    deploy = 'deploy'\n",
    "    model_details = {\n",
    "        \"name\" : final_model.name,\n",
    "        \"version\": final_model.version,\n",
    "        \"properties\": final_model.properties,\n",
    "        \"nextstep\": \"deploy\"\n",
    "    }\n",
    "    print(model_details)\n",
    "else:\n",
    "    deploy = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in final_model.properties:\n",
    "    print(x)\n",
    "    print(final_model.properties[x])\n",
    "\n",
    "\n",
    "print (final_model.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "outputfolder = 'run_outputs'\n",
    "os.makedirs(outputfolder, exist_ok=True)\n",
    "\n",
    "if (final_model_version != inital_model_version):\n",
    "    print('new model registered')\n",
    "    with open(os.path.join(outputfolder, 'deploy_details.json'), \"w+\") as f:\n",
    "        f.write(str(model_details))\n",
    "    model_name = prefix\n",
    "    model_list = Model.list(ws, name=model_name, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model_file_name = prefix + '.pkl'\n",
    "    shutil.copyfile(model_file_name,  os.path.join(outputfolder,model_file_name))\n",
    "    \n",
    "    #create model.yml file.\n",
    "    with open(os.path.join(outputfolder, 'model.yml'), \"w+\") as f:\n",
    "        f.write('$schema: https://azuremlschemas.azureedge.net/latest/model.schema.json \\n')\n",
    "        f.write('name: ' + model_details['name'] + '\\n')\n",
    "        #f.write('version: ' + str(final_model.version)  + '\\n')\n",
    "        f.write('path: ' + prefix + '.pkl \\n')\n",
    "        f.write('description: Model created from local file. \\n')\n",
    "        if len(final_model.properties) > 0:\n",
    "            f.write('properties: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            f.write('\\n')\n",
    "            f.write('tags: ')\n",
    "            f.write(json.dumps(final_model.properties))\n",
    "            \n",
    "    \n",
    "with open(os.path.join(outputfolder, 'run_details.json'), \"w+\") as f:\n",
    "    print(run_details)\n",
    "    f.write(str(run_details))\n",
    "\n",
    "with open(os.path.join(outputfolder, \"run_number.json\"), \"w+\") as f:\n",
    "    f.write(run_details['runId'])\n",
    "    \n",
    "with open(os.path.join(outputfolder, \"deploy.txt\"), \"w+\") as f:\n",
    "    f.write(deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "def published_pipeline_to_pipeline_endpoint(\n",
    "    workspace,\n",
    "    published_pipeline,\n",
    "    pipeline_endpoint_name,\n",
    "    pipeline_endpoint_description=\"Endpoint to Training pipeline\",\n",
    "):\n",
    "    try:\n",
    "        pipeline_endpoint = PipelineEndpoint.get(\n",
    "            workspace=workspace, name=pipeline_endpoint_name\n",
    "        )\n",
    "        print(\"using existing PipelineEndpoint...\")\n",
    "        pipeline_endpoint.add_default(published_pipeline)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        # create PipelineEndpoint if it doesn't exist\n",
    "        print(\"PipelineEndpoint does not exist, creating one for you...\")\n",
    "        pipeline_endpoint = PipelineEndpoint.publish(\n",
    "            workspace=workspace,\n",
    "            name=pipeline_endpoint_name,\n",
    "            pipeline=published_pipeline,\n",
    "            description=pipeline_endpoint_description\n",
    "        )\n",
    "\n",
    "if deploy == 'deploy':\n",
    "    print('deploy Training Pipeline')\n",
    "    pipeline_endpoint_name = 'Training Pipeline'\n",
    "    pipeline_endpoint_description = 'Endpoint to Training pipeline'\n",
    "\n",
    "    published_pipeline = pipeline.publish(name=pipeline_endpoint_name,\n",
    "                                         description=pipeline_endpoint_description,\n",
    "                                         continue_on_step_failure=False)\n",
    "\n",
    "    published_pipeline_to_pipeline_endpoint(\n",
    "        workspace=ws,\n",
    "        published_pipeline=published_pipeline,\n",
    "        pipeline_endpoint_name=pipeline_endpoint_name,\n",
    "        pipeline_endpoint_description=pipeline_endpoint_description\n",
    "    )\n",
    "else:\n",
    "    print('do not publish pipeline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
